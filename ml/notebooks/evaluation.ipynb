{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "This notebook is used to evaluate the performance of the trained model on the test dataset. It includes metrics such as accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from your_model_file import YourModelClass  # Replace with your actual model class\n",
    "from your_data_loader import load_test_data  # Replace with your actual data loading function\n",
    "\n",
    "# Load the model\n",
    "model = YourModelClass()  # Initialize your model\n",
    "model.load_state_dict(torch.load('path_to_your_model_weights.pth'))  # Load weights\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Load test data\n",
    "test_loader = load_test_data()  # Load your test dataset\n",
    "\n",
    "# Initialize lists to store predictions and true labels\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(all_labels, all_preds))\n",
    "\n",
    "# Generate confusion matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(np.unique(all_labels)))\n",
    "plt.xticks(tick_marks, np.unique(all_labels))\n",
    "plt.yticks(tick_marks, np.unique(all_labels))\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}